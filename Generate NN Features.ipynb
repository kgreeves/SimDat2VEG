{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#Loading Data\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from itertools import cycle\n",
    "\n",
    "#To build ML model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_XYZformat(fln):\n",
    "    #Modified from https://github.com/pele-python/pele/blob/master/pele/utils/xyz.py\n",
    "    fin = open(fln,'r')\n",
    "    natoms = int(fin.readline())\n",
    "    comment = fin.readline()[:-1]\n",
    "    coords = np.zeros([natoms, 3], dtype=\"float64\")\n",
    "    atomtypes = []\n",
    "    for x in coords:\n",
    "        line = fin.readline().split()\n",
    "        atomtypes.append(line[0])\n",
    "        x[:] = list(map(float, line[1:4]))\n",
    "    fin.close()\n",
    "    return (coords, comment, atomtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_xyz(fln, coords, title=\"\", atomtypes=(\"A\",)):\n",
    "    fout = open(fln,'w')\n",
    "    fout.write(\"%d\\n%s\\n\" % (coords.size / 3, title))\n",
    "    for x, atomtype in zip(coords.reshape(-1, 3), cycle(atomtypes)):\n",
    "        fout.write(\"%s %.18g %.18g %.18g\\n\" % (atomtype, x[0], x[1], x[2]))\n",
    "    fout.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_solute(coords,com_selection):\n",
    "    centered_coords = coords - com_selection.mean(axis=0)\n",
    "    return centered_coords\n",
    "\n",
    "def wrap_cell(coords,metadata,cellparam_np):\n",
    "#def wrap_cell(coords,box_length):    \n",
    "    #cellparam_np = np.array((box_length,box_length,box_length))\n",
    "    \n",
    "    wrapped_traj = coords + (metadata[\"box_length\"]*(0.5) < np.abs(coords))*cellparam_np*(np.sign(cellparam_np*(0.5)-coords))\n",
    "\n",
    "    return wrapped_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorient_molecule(newX,newY,newZ):\n",
    "    #Confirm that new coordinate vectors are unit vectors\n",
    "    newX = (1.0/np.linalg.norm(newX)*newX)\n",
    "    newY = (1.0/np.linalg.norm(newY)*newY)\n",
    "    newZ = (1.0/np.linalg.norm(newZ)*newZ)\n",
    "    \n",
    "    newZ_xy = np.linalg.norm(newZ[:2])\n",
    "    \n",
    "    precession_alpha  =  np.arctan2(newY[0]*newZ[1]-newY[1]*newZ[0],newX[0]*newZ[1]-newX[1]*newZ[0])\n",
    "    nutation_beta     =  np.arctan2(newZ_xy,newZ[2])\n",
    "    rotation_gamma    =  (-1.0)*np.arctan2((-1.0)*newZ[0],newZ[1])\n",
    "    \n",
    "    return precession_alpha, nutation_beta, rotation_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genF_bond(coords,topology):\n",
    "    bond_lengths = np.zeros((len(topology),1))\n",
    "    \n",
    "    for bond in range(len(topology)):\n",
    "        pair_atoms = coords[topology[bond]]\n",
    "        bond_lengths[bond] = np.linalg.norm(pair_atoms[0]-pair_atoms[1])\n",
    "    \n",
    "    return bond_lengths\n",
    "\n",
    "def genF_angles(coords,topology):\n",
    "    def compute_angle(coords,center_pt,end_pts):\n",
    "        ba = coords[end_pts[0]] - coords[center_pt[0]]\n",
    "        bc = coords[end_pts[1]] - coords[center_pt[0]]\n",
    "    \n",
    "        cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "        angle = np.arccos(cosine_angle)\n",
    "            \n",
    "        return np.degrees(angle)\n",
    "    \n",
    "    angles_and_centers = []\n",
    "    \n",
    "    for pair1 in range(len(topology)-1):\n",
    "        for pair2 in range(pair1+1,len(topology)):\n",
    "            result_list = list(topology[pair1])\n",
    "            result_list.extend(x for x in topology[pair2] if x not in result_list )\n",
    "            if(len(result_list)==3):\n",
    "                angles_and_centers.append((list(set(topology[pair1]).intersection(topology[pair2])),\n",
    "                                           list(set(topology[pair1]).symmetric_difference(topology[pair2]))))\n",
    "    \n",
    "    bond_angles = np.zeros((len(angles_and_centers),1))\n",
    "    for i,three_atoms in enumerate(angles_and_centers):\n",
    "        bond_angles[i] = compute_angle(coords,three_atoms[0],three_atoms[1])  \n",
    "    \n",
    "    return bond_angles\n",
    "\n",
    "def genF_dihedrals(coords,topology):\n",
    "\n",
    "####-------------------------------------------   \n",
    "    def compute_dihedral(coords, dihedrals_and_centers):\n",
    "        \n",
    "        u1,u2,u3,u4 = coords[dihedrals_and_centers]\n",
    "        #print(u1,u2,u3,u4)\n",
    "\n",
    "        a1 = u2 - u1\n",
    "        a2 = u3 - u2\n",
    "        a3 = u4 - u3\n",
    "\n",
    "        v1 = np.cross(a1, a2)\n",
    "        v1 = v1 / (v1 * v1).sum(-1)**0.5\n",
    "        v2 = np.cross(a2, a3)\n",
    "        v2 = v2 / (v2 * v2).sum(-1)**0.5\n",
    "        porm = np.sign((v1 * a3).sum(-1))\n",
    "        rad = np.arccos((v1*v2).sum(-1) / ((v1**2).sum(-1) * (v2**2).sum(-1))**0.5)\n",
    "        if not porm == 0:\n",
    "            rad = rad * porm\n",
    "\n",
    "        return np.degrees(rad)\n",
    " ####-------------------------------------------   \n",
    "    \n",
    "    dihedrals_and_centers = []\n",
    "\n",
    "    for pair1 in range(len(topology)-2):\n",
    "        for pair2 in range(pair1+1,len(topology)-1):\n",
    "            for pair3 in range(pair2+1,len(topology)):\n",
    "                result_list = list(topology[pair1])\n",
    "                result_list.extend(x for x in topology[pair2] if x not in result_list )\n",
    "                result_list.extend(x for x in topology[pair3] if x not in result_list[2:] )\n",
    "                if(len(result_list)==4):\n",
    "                    dihedrals_and_centers.append(result_list)\n",
    "\n",
    "    for four_atoms in dihedrals_and_centers:\n",
    "        for i in topology:\n",
    "            if [four_atoms[0],four_atoms[2]] == i:\n",
    "                four_atoms[0],four_atoms[1] = four_atoms[1], four_atoms[0]\n",
    "\n",
    "    bond_dihedrals= np.zeros((len(dihedrals_and_centers),1))\n",
    "    for i,four_atoms in enumerate(dihedrals_and_centers):\n",
    "        bond_dihedrals[i] = compute_dihedral(coords,four_atoms)     \n",
    "    \n",
    "    return bond_dihedrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solvent_COMs(coords,metadata):\n",
    "    \n",
    "    #Definitions of numbers of atoms\n",
    "    n_atoms_solute = metadata[\"n_atoms_solute\"]; total_atoms = metadata[\"n_atoms\"];\n",
    "    n_atoms_solvent = len(metadata[\"solvent_indices\"]);\n",
    "    \n",
    "    num_solvent = int((total_atoms-n_atoms_solute)/n_atoms_solvent)\n",
    "    \n",
    "    #Generating a new numpy array for the coordinates with reconstructed solvent\n",
    "    reconstructed_solvent_POS = np.zeros_like(coords)\n",
    "    reconstructed_solvent_POS[:n_atoms_solute,:] = coords[:n_atoms_solute,:]\n",
    "    \n",
    "    #Reconstruct solvent at boundaries and compute COMs\n",
    "    solvent_COMs    = np.zeros((num_solvent,3))\n",
    "    solvent_COM_dist = np.zeros((num_solvent,1)) \n",
    "    \n",
    "    for solvent_mol in range(num_solvent):\n",
    "        #Grab POS for all atoms in solvent molecule\n",
    "        solvent_mol_coords = coords[n_atoms_solute+solvent_mol*n_atoms_solvent:\n",
    "                                    n_atoms_solute+(solvent_mol+1)*n_atoms_solvent]\n",
    "        \n",
    "        bool_solvent_mol_coords = (np.abs(solvent_mol_coords - solvent_mol_coords[0,:]) > 0.5*metadata[\"box_length\"])\n",
    "\n",
    "        solvent_mol_coords = solvent_mol_coords+bool_solvent_mol_coords*np.sign(solvent_mol_coords[0,:])*metadata[\"box_length\"]\n",
    "        reconstructed_solvent_POS[n_atoms_solute+solvent_mol*n_atoms_solvent:\n",
    "                                  n_atoms_solute+(solvent_mol+1)*n_atoms_solvent] = solvent_mol_coords\n",
    "\n",
    "        solvent_COMs[solvent_mol]      = np.average(solvent_mol_coords,axis=0)\n",
    "        solvent_COM_dist[solvent_mol]  = np.linalg.norm(np.average(solvent_mol_coords,axis=0))\n",
    "        \n",
    "    return reconstructed_solvent_POS, solvent_COMs, solvent_COM_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_netForce_perSolvent(forces,metadata):\n",
    "    #Definitions of numbers of atoms\n",
    "    n_atoms_solute = metadata[\"n_atoms_solute\"]; total_atoms = metadata[\"n_atoms\"];\n",
    "    n_atoms_solvent = len(metadata[\"solvent_indices\"]);\n",
    "    \n",
    "    num_solvent = int((total_atoms-n_atoms_solute)/n_atoms_solvent)\n",
    "    \n",
    "    #Array to store X,Y,Z components of force\n",
    "    force_per_solvent    = np.zeros((num_solvent,3))\n",
    "    \n",
    "    for solvent_mol in range(num_solvent):\n",
    "        #Grab forces for all atoms in solvent molecule\n",
    "        solvent_mol_forces = forces[n_atoms_solute+solvent_mol*n_atoms_solvent:\n",
    "                                    n_atoms_solute+(solvent_mol+1)*n_atoms_solvent]\n",
    "        force_per_solvent[solvent_mol] = np.sum(solvent_mol_forces,axis=0)\n",
    "        \n",
    "    return force_per_solvent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_solvent_orientation(coords,metadata,solvent_COM,nearest_15_solv_index):\n",
    "    \n",
    "    #solvent_COM[nearest_15_solv_index]\n",
    "    \n",
    "\n",
    "    \n",
    "    solvent_angles = np.zeros((len(nearest_15_solv_index),1))\n",
    "    \n",
    "    for i in range(len(nearest_15_solv_index)):\n",
    "        a1 =  (-1.0)*solvent_COM[nearest_15_solv_index][i]\n",
    "        a2 =  coords[(metadata[\"n_atoms_solute\"]+len(metadata[\"solvent_indices\"])*nearest_15_solv_index)+metadata[\"solvent_indices\"][\"N\"]][i]-solvent_COM[nearest_15_solv_index][i]\n",
    "        \n",
    "        cosine_angle = np.dot(a1, a2) / (np.linalg.norm(a1) * np.linalg.norm(a2))\n",
    "        solvent_angles[i] = np.arccos(cosine_angle)\n",
    "            \n",
    "        #return np.degrees(angle)\n",
    "    \n",
    "    return np.degrees(solvent_angles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_solute(coords,x_reference_atom,y_reference_atom):\n",
    "    # Here, the x_reference_atom will be aligned to the x-axis. The y_reference_atom serves to define the\n",
    "    # XY-plane, but as it is not guaranteed to be orthogonal to the new x-axis, the new_Y is the orthognal direction\n",
    "    # which falls in this XY-plane. the new Z-axis is simply the cross-product of these two new vectors.\n",
    "    #\n",
    "    # Given the new set of axis, the Euler angles can be computed in order to construct a rotation matrix used to\n",
    "    # transform all coordinates from the local coordinate system into the world coordinate system.\n",
    "    \n",
    "    #Define new X axis\n",
    "    newX = x_reference_atom\n",
    "    newX = (1.0/np.linalg.norm(newX))*newX\n",
    "    #Use a second point to define the plane.\n",
    "    #I.e. find a vector n orthogonal to a that is in the plane which contains a and b.\n",
    "    refY = y_reference_atom\n",
    "    newY = np.cross(newX,np.cross(newX,(1.0/np.linalg.norm(refY))*refY))\n",
    "    newY = (1.0/np.linalg.norm(newY))*newY\n",
    "\n",
    "    #Define new Z as perpendicular to plane defined by newX and newY\n",
    "    newZ = np.cross(newX,newY)\n",
    "    newZ = (1.0/np.linalg.norm(newZ)*newZ)\n",
    "\n",
    "    #Apply reoriented molecules\n",
    "    alpha,beta,gamma = reorient_molecule(newX,newY,newZ)\n",
    "\n",
    "    #Define Rotation Matrix (Z1X2Z3, Euler Angles)\n",
    "\n",
    "    RotMatrix = np.array([[np.cos(alpha)*np.cos(gamma)-np.cos(beta)*np.sin(alpha)*np.sin(gamma),-np.cos(alpha)*np.sin(gamma)-np.cos(beta)*np.cos(gamma)*np.sin(alpha),np.sin(alpha)*np.sin(beta)],\n",
    "                          [np.cos(gamma)*np.sin(alpha)+np.cos(alpha)*np.cos(beta)*np.sin(gamma),np.cos(alpha)*np.cos(beta)*np.cos(gamma)-np.sin(alpha)*np.sin(gamma),-np.cos(alpha)*np.sin(beta)],\n",
    "                          [np.sin(beta)*np.sin(gamma),np.cos(gamma)*np.sin(beta),np.cos(beta)]])\n",
    "\n",
    "    POS_rotated = np.matmul(RotMatrix,np.transpose(coords)).transpose()\n",
    "    \n",
    "    return POS_rotated, RotMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_POS_for_nearest(coords,metadata,num_nearest,AtomNames):\n",
    "\n",
    "    nearest_solv_index = metadata[\"Solvent_COM_Indices\"][:num_nearest]\n",
    "\n",
    "    solute_and_nearest = np.zeros(((metadata[\"n_atoms_solute\"]+len(metadata[\"solvent_indices\"])*num_nearest),3))\n",
    "    solute_and_nearest[:metadata[\"n_atoms_solute\"],:] = coords[:metadata[\"n_atoms_solute\"],:]\n",
    "    \n",
    "    for i, solv_index in enumerate(nearest_solv_index):\n",
    "        solute_and_nearest[metadata[\"n_atoms_solute\"]+i*len(metadata[\"solvent_indices\"]):\n",
    "                           metadata[\"n_atoms_solute\"]+(i+1)*len(metadata[\"solvent_indices\"]),:] = coords[metadata[\"n_atoms_solute\"]+solv_index*len(metadata[\"solvent_indices\"]):\n",
    "                           metadata[\"n_atoms_solute\"]+(solv_index+1)*len(metadata[\"solvent_indices\"]),:]\n",
    "\n",
    "    #solute_and_nearest = np.matmul(metadata[\"RotationMatrix\"],np.transpose(solute_and_nearest)).transpose()\n",
    "    \n",
    "    write_xyz(\"AQ_\"+str(num_nearest)+\"nearestACN.xyz\", solute_and_nearest, title=\"\", atomtypes=AtomNames)\n",
    "    \n",
    "    return solute_and_nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian_to_spherical(coords):\n",
    "    \n",
    "    spherical_coords = np.zeros_like(coords)\n",
    "    \n",
    "    spherical_coords[:,0]   = np.linalg.norm(coords,axis=1) #rho\n",
    "    spherical_coords[:,1]   = np.arccos(coords[:,2]/np.linalg.norm(coords,axis=1)) #theta\n",
    "    spherical_coords[:,2]   = np.arctan2(coords[:,1],coords[:,0]) #phi\n",
    "    \n",
    "    return spherical_coords\n",
    "\n",
    "def spherical_to_cartesian(coords):\n",
    "    \n",
    "    cartesian_coords = np.zeros_like(coords)\n",
    "    \n",
    "    cartesian_coords[:,0]   = coords[:,0]*np.sin(coords[:,1])*np.cos(coords[:,2]) #x\n",
    "    cartesian_coords[:,1]   = coords[:,0]*np.sin(coords[:,1])*np.sin(coords[:,2]) #y\n",
    "    cartesian_coords[:,2]   = coords[:,0]*np.cos(coords[:,1]) #z\n",
    "    \n",
    "    return cartesian_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"topology_solute\"       : [[4,5],[4,22],[22,15],[15,23],[15,16],[16,19],[16,18],\n",
    "                               [18,21],[18,17],[17,20],[17,3],[3,22],[3,6],[6,7],\n",
    "                               [6,1],[1,12],[12,14],[12,10],[10,13],[10,0],[0,11],\n",
    "                               [0,8],[8,9],[8,2],[2,1],[2,4]],\n",
    "    \n",
    "    \"n_atoms\"               : 594,\n",
    "    \"n_atoms_solute\"        : 24,\n",
    "    \"box_length\"            : 20.55,\n",
    "    \n",
    "    \"solvent_indices\"       : {\"CC\": 0,\n",
    "                               \"C\" : 1,\n",
    "                               \"H1\": 2,\n",
    "                               \"H2\": 3,\n",
    "                               \"H3\": 4,\n",
    "                               \"N\" : 5\n",
    "                              }\n",
    "        \n",
    "}\n",
    "\n",
    "\n",
    "#Create a representation of topology with reversed indices\n",
    "topology_reverse = []\n",
    "for i in metadata[\"topology_solute\"]:\n",
    "    topology_reverse.append(list(i))\n",
    "for i in topology_reverse:\n",
    "    i.reverse()\n",
    "metadata[\"topology_reverse\"] = topology_reverse\n",
    "\n",
    "translation_vectors = np.array([[metadata[\"box_length\"],metadata[\"box_length\"],metadata[\"box_length\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_analyze_trajstep(POS_fln,FRC_fln):\n",
    "    #Load Data\n",
    "    POS, _, AtomNames = read_XYZformat(str(POS_fln))\n",
    "    FRC, _, AtomNames = read_XYZformat(str(FRC_fln))\n",
    "\n",
    "    #Center and Wrap all solvent molecules. Only necessary for POS as criteria are only \n",
    "    #based on POS and the indices do not change\n",
    "    cPOS = center_solute(POS,POS[:metadata[\"n_atoms_solute\"]])  #initial translation of entire cell. COM may be incorrect if atoms need to be wrapped\n",
    "    #cwPOS = wrap_cell(cPOS,metadata[\"box_length\"])\n",
    "    cwPOS = wrap_cell(cPOS,metadata,translation_vectors)\n",
    "    cwPOS = center_solute(cwPOS,cwPOS[:metadata[\"n_atoms_solute\"]]) #second re-centering after all atoms are wrapped\n",
    "\n",
    "    #Features for positions: SOLUTE\n",
    "    gF_bonds = genF_bond(cwPOS,metadata[\"topology_solute\"])\n",
    "    gF_angles = genF_angles(cwPOS,metadata[\"topology_solute\"])\n",
    "    gF_dihedrals = genF_dihedrals(cwPOS,metadata[\"topology_solute\"])\n",
    "    #Features for positions: SOLVENT\n",
    "    _, solvent_COM, solvent_COM_dist = generate_solvent_COMs(cwPOS,metadata)\n",
    "    metadata[\"Solvent_COM_Indices\"] = np.argsort(solvent_COM_dist, axis=0).flatten()\n",
    "    nearest_15_solv_index = np.argsort(solvent_COM_dist,axis=0)[:15,:].flatten()\n",
    "\n",
    "    gF_solvent_distance   = solvent_COM_dist[nearest_15_solv_index]\n",
    "    gF_solvent_position   = cartesian_to_spherical(solvent_COM[nearest_15_solv_index])\n",
    "\n",
    "    gF_solvent_orienation = compute_solvent_orientation(cwPOS,metadata,solvent_COM,nearest_15_solv_index)\n",
    "\n",
    "    cwrPOS,metadata[\"RotationMatrix\"] = align_solute(cwPOS,0.5*(cwPOS[16]+cwPOS[18]),cwPOS[7])\n",
    "    _ = generate_POS_for_nearest(cwrPOS,metadata,15,AtomNames)\n",
    "\n",
    "    #Features for forces\n",
    "    #Transform forces using computing rotation matrix (to be with respect to local coordinates)\n",
    "\n",
    "    rFRC = np.matmul(metadata[\"RotationMatrix\"],np.transpose(FRC)).transpose()\n",
    "\n",
    "    gF_force_per_solvent = compute_netForce_perSolvent(rFRC,metadata)\n",
    "    gF_force_per_solute_atom = rFRC[:metadata[\"n_atoms_solute\"],:]\n",
    "    \n",
    "    #Summarize shape of each feature to reference when normalizing data\n",
    "    #feature_shapes = [np.shape(gF_solvent_distance),np.shape(gF_solvent_position),\n",
    "    #                  np.shape(gF_solvent_orienation),np.shape(gF_force_per_solvent),\n",
    "    #                  np.shape(gF_force_per_solute_atom)]\n",
    "    #gF_concat = np.concatenate((gF_solvent_distance,gF_solvent_position,gF_solvent_orienation,\n",
    "    #                            gF_force_per_solvent,gF_force_per_solute_atom),axis=None)\n",
    "    \n",
    "    #ORIGINAL FEATURES\n",
    "    feature_shapes = [np.shape(gF_solvent_position),np.shape(gF_solvent_orienation),\n",
    "                      np.shape(gF_force_per_solvent),np.shape(gF_force_per_solute_atom)]\n",
    "\n",
    "    gF_concat = np.concatenate((gF_solvent_position,gF_solvent_orienation,\n",
    "                               gF_force_per_solvent,gF_force_per_solute_atom),axis=None)\n",
    "    #END ORIGINAL FEATURES\n",
    "    \n",
    "    #TEST FEATURES\n",
    "    #feature_shapes = [np.shape(gF_solvent_position),np.shape(gF_force_per_solute_atom)]\n",
    "\n",
    "    #gF_concat = np.concatenate((gF_solvent_position,gF_force_per_solute_atom),axis=None)\n",
    "    #END TEST FEATURES\n",
    "    return gF_concat, feature_shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    num_data=499\n",
    "    #num_data=2\n",
    "    feature_normalization = {}\n",
    "    \n",
    "    #Load the Vertical Energy Gaps for the System. These will be used as the reference to train the ML model.\n",
    "    test_y = np.loadtxt(\"DATA/AQ_AQ-_VEE.dat\").astype(np.float32)\n",
    "    test_y = np.reshape(test_y,(len(test_y),1))\n",
    "    \n",
    "    #Initialize the arrays and lists used to temporarily store and construct the list of features\n",
    "    featurearray=None\n",
    "    featurelist = []\n",
    "    for i in range(num_data):\n",
    "        temp_array, temp_feature_shapes = load_and_analyze_trajstep(\"DATA/POS/POS_frame_\"+str(i),\"DATA/FRC/FRC_frame_\"+str(i))\n",
    "        featurelist.append(temp_array)\n",
    "    featurearray = np.asarray(featurelist)\n",
    "    \n",
    "    def unison_shuffled_copies(a, b):\n",
    "        assert len(a) == len(b)\n",
    "        p = np.random.permutation(len(a))\n",
    "        return a[p], b[p]\n",
    "    \n",
    "    #To avoid training the ANN to sequential data, we eliminate possible time-dependence by shuffling the data.\n",
    "    #features and corresponding VEE gaps must be shuffled identically to correspond to one another during the\n",
    "    #training process.\n",
    "    featurearray,test_y = unison_shuffled_copies(featurearray,test_y)\n",
    "       \n",
    "    #Define split of data (80% train: 20% validation)\n",
    "    train_size = int(0.8*np.shape(featurearray)[0])\n",
    "    \n",
    "    #Define training and validation sets\n",
    "    X_train = featurearray[:train_size]\n",
    "    y_train = test_y[:train_size]\n",
    "    X_val = featurearray[train_size:]\n",
    "    y_val = test_y[train_size:num_data]\n",
    "    \n",
    "    #Normalized Training and Validation Arrays\n",
    "    nX_train = np.zeros_like(X_train)\n",
    "    nX_val   = np.zeros_like(X_val)\n",
    "    \n",
    "    #NORMALIZE EACH GENERATED FEATURE (gF) SUCH THAT MEAN = 0 AND VARIANCE = 1\n",
    "    #Normalization should only be computed using X_train set. The mean and variance should\n",
    "    #then be stored and passed in order to shift the X_val and future X_test data \n",
    "    #appropriately to feed into the model.\n",
    "    \n",
    "    advance=0;\n",
    "    for i in range(len(temp_feature_shapes)):\n",
    "        num_feat=temp_feature_shapes[i][0] ; dim=temp_feature_shapes[i][1];\n",
    "        temp_recon = X_train[:,advance:advance+(num_feat*dim)].reshape(len(X_train),num_feat,dim)\n",
    "        temp_recon = temp_recon.reshape(len(X_train)*temp_feature_shapes[i][0],temp_feature_shapes[i][1])\n",
    "\n",
    "        #Convert Polar to Cartesian, Compute Distance (r in polar), \n",
    "        if(i==0):\n",
    "            #print(X_train[:,advance:advance+(num_feat*dim)])\n",
    "            #print(temp_recon)\n",
    "            solve_cart = spherical_to_cartesian(temp_recon)\n",
    "            solvent_distances = np.linalg.norm(solve_cart,axis=1).reshape(len(temp_recon),1)\n",
    "    \n",
    "            ##Min-Max Normalization\n",
    "            solvent_distances_min = np.min(solvent_distances)\n",
    "            solvent_distances_max = np.max(solvent_distances)\n",
    "            std_solvent_minmaxNorm = (solvent_distances-solvent_distances_min+1E-16)/(solvent_distances_max-solvent_distances_min)\n",
    "            nSolvent_cart = std_solvent_minmaxNorm*solve_cart*(1.0/solvent_distances)\n",
    "            nSolvent_spherical = cartesian_to_spherical(nSolvent_cart)\n",
    "            nX_train[:,advance:advance+(num_feat*dim)] = nSolvent_spherical.reshape(len(X_train),num_feat*dim)\n",
    "            \n",
    "            #Update Feature Normalization Dictionary\n",
    "            feature_normalization[\"gF_solvent_position_min\"] = solvent_distances_min\n",
    "            feature_normalization[\"gF_solvent_position_max\"] = solvent_distances_max\n",
    "\n",
    "        if(i==1):\n",
    "            temp_min = np.min(temp_recon)\n",
    "            temp_max = np.max(temp_recon)\n",
    "            temp_minmaxNorm = (temp_recon-temp_min+1E-16)/(temp_max-temp_min)\n",
    "            nX_train[:,advance:advance+(num_feat*dim)] = temp_minmaxNorm.reshape(len(X_train),num_feat*dim)\n",
    "            \n",
    "            #Update Feature Normalization Dictionary\n",
    "            feature_normalization[\"gF_solvent_orienation_min\"] = temp_min\n",
    "            feature_normalization[\"gF_solvent_orienation_max\"] = temp_max\n",
    "        \n",
    "        if(i==2 or i==3):\n",
    "            force_mag = np.linalg.norm(temp_recon,axis=1).reshape(len(temp_recon),1)\n",
    "            force_mean = np.mean(force_mag)\n",
    "            force_std = np.std(force_mag)\n",
    "            force_zScoreNorm = (force_mag-force_mean)/(force_std)\n",
    "            force_zScoreNorm = force_zScoreNorm*(1.0/force_mag)*temp_recon\n",
    "            nX_train[:,advance:advance+(num_feat*dim)] = force_zScoreNorm.reshape(len(X_train),num_feat*dim)\n",
    "            \n",
    "            if(i==2):\n",
    "                #Update Feature Normalization Dictionary\n",
    "                feature_normalization[\"gF_force_per_solvent_mean\"] = force_mean\n",
    "                feature_normalization[\"gF_force_per_solvent_std\"] = force_std\n",
    "            \n",
    "            if(i==3):\n",
    "                #Update Feature Normalization Dictionary\n",
    "                feature_normalization[\"gF_force_per_solute_atom_mean\"] = force_mean\n",
    "                feature_normalization[\"gF_force_per_solute_atom_std\"] = force_std\n",
    "                \n",
    "        advance+=(num_feat*dim)\n",
    "\n",
    "    advance = 0\n",
    "    \n",
    "    for i in range(len(temp_feature_shapes)):\n",
    "        num_feat=temp_feature_shapes[i][0] ; dim=temp_feature_shapes[i][1];\n",
    "        temp_recon = X_val[:,advance:advance+(num_feat*dim)].reshape(len(X_val),num_feat,dim)\n",
    "        temp_recon = temp_recon.reshape(len(X_val)*temp_feature_shapes[i][0],temp_feature_shapes[i][1])\n",
    "        \n",
    "        if(i==0):\n",
    "            solve_cart = spherical_to_cartesian(temp_recon)\n",
    "            solvent_distances = np.linalg.norm(solve_cart,axis=1).reshape(len(temp_recon),1)\n",
    "    \n",
    "            ##Min-Max Normalization\n",
    "            solvent_distances_min = feature_normalization[\"gF_solvent_position_min\"]\n",
    "            solvent_distances_max = feature_normalization[\"gF_solvent_position_max\"]\n",
    "            std_solvent_minmaxNorm = (solvent_distances-solvent_distances_min+1E-16)/(solvent_distances_max-solvent_distances_min)\n",
    "            nSolvent_cart = std_solvent_minmaxNorm*solve_cart*(1.0/solvent_distances)\n",
    "            nSolvent_spherical = cartesian_to_spherical(nSolvent_cart)\n",
    "            nX_val[:,advance:advance+(num_feat*dim)] = nSolvent_spherical.reshape(len(X_val),num_feat*dim)\n",
    "        \n",
    "        if(i==1):\n",
    "            temp_min = feature_normalization[\"gF_solvent_orienation_min\"]\n",
    "            temp_max = feature_normalization[\"gF_solvent_orienation_max\"]\n",
    "            temp_minmaxNorm = (temp_recon-temp_min+1E-16)/(temp_max-temp_min)\n",
    "            nX_val[:,advance:advance+(num_feat*dim)] = temp_minmaxNorm.reshape(len(X_val),num_feat*dim)\n",
    "            \n",
    "        if(i==2):\n",
    "            force_mag = np.linalg.norm(temp_recon,axis=1).reshape(len(temp_recon),1)\n",
    "            force_mean = feature_normalization[\"gF_force_per_solvent_mean\"]\n",
    "            force_std = feature_normalization[\"gF_force_per_solvent_std\"]\n",
    "            force_zScoreNorm = (force_mag-force_mean)/(force_std)\n",
    "            force_zScoreNorm = force_zScoreNorm*(1.0/force_mag)*temp_recon\n",
    "            nX_val[:,advance:advance+(num_feat*dim)] = force_zScoreNorm.reshape(len(X_val),num_feat*dim)\n",
    "            \n",
    "        if(i==3):\n",
    "            force_mag = np.linalg.norm(temp_recon,axis=1).reshape(len(temp_recon),1)\n",
    "            force_mean = feature_normalization[\"gF_force_per_solute_atom_mean\"]\n",
    "            force_std = feature_normalization[\"gF_force_per_solute_atom_std\"]\n",
    "            force_zScoreNorm = (force_mag-force_mean)/(force_std)\n",
    "            force_zScoreNorm = force_zScoreNorm*(1.0/force_mag)*temp_recon\n",
    "            nX_val[:,advance:advance+(num_feat*dim)] = force_zScoreNorm.reshape(len(X_val),num_feat*dim)\n",
    "        \n",
    "        advance+=(num_feat*dim)\n",
    "        \n",
    "    \n",
    "    \n",
    "    np.save(\"DATA/X_train\",nX_train)\n",
    "    np.save(\"DATA/X_val\",nX_val)\n",
    "    np.save(\"DATA/y_train\",y_train)\n",
    "    np.save(\"DATA/y_val\",y_val)\n",
    "    np.save(\"DATA/feature_normalization\",feature_normalization)\n",
    "        \n",
    "    #return feature_normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Normalized_test_features(TEST_POS_DIR,TEST_FRC_DIR,num_data):\n",
    "    \n",
    "    #Load normalization constants generated using training data.\n",
    "    feature_normalization = np.load(\"DATA/feature_normalization.npy\",allow_pickle='TRUE').item()\n",
    "    \n",
    "    #Initialize the arrays and lists necessary to \n",
    "    featurearray=None\n",
    "    featurelist = []\n",
    "    for i in range(num_data):\n",
    "        temp_array, temp_feature_shapes = load_and_analyze_trajstep(\"DATA/TEST/\"+str(TEST_POS_DIR)+\"/POS_frame_\"+str(i),\"DATA/TEST/\"+str(TEST_FRC_DIR)+\"/FRC_frame_\"+str(i))\n",
    "        featurelist.append(temp_array)\n",
    "    \n",
    "    \n",
    "    X_test = np.asarray(featurelist)\n",
    "    #Normalized Training and Validation Arrays\n",
    "    nX_test = np.zeros_like(X_test)\n",
    "    \n",
    "    advance = 0\n",
    "    \n",
    "    #for i in range(len(temp_feature_shapes)):\n",
    "    for i in range(4):\n",
    "        num_feat=temp_feature_shapes[i][0] ; dim=temp_feature_shapes[i][1];\n",
    "        temp_recon = X_test[:,advance:advance+(num_feat*dim)].reshape(len(X_test),num_feat,dim)\n",
    "        temp_recon = temp_recon.reshape(len(X_test)*temp_feature_shapes[i][0],temp_feature_shapes[i][1])\n",
    "        \n",
    "        if(i==0):\n",
    "            solve_cart = spherical_to_cartesian(temp_recon)\n",
    "            solvent_distances = np.linalg.norm(solve_cart,axis=1).reshape(len(temp_recon),1)\n",
    "    \n",
    "            ##Min-Max Normalization\n",
    "            solvent_distances_min = feature_normalization[\"gF_solvent_position_min\"]\n",
    "            solvent_distances_max = feature_normalization[\"gF_solvent_position_max\"]\n",
    "            std_solvent_minmaxNorm = (solvent_distances-solvent_distances_min+1E-16)/(solvent_distances_max-solvent_distances_min)\n",
    "            nSolvent_cart = std_solvent_minmaxNorm*solve_cart*(1.0/solvent_distances)\n",
    "            nSolvent_spherical = cartesian_to_spherical(nSolvent_cart)\n",
    "            nX_test[:,advance:advance+(num_feat*dim)] = nSolvent_spherical.reshape(len(X_test),num_feat*dim)\n",
    "        \n",
    "        if(i==1):\n",
    "            temp_min = feature_normalization[\"gF_solvent_orienation_min\"]\n",
    "            temp_max = feature_normalization[\"gF_solvent_orienation_max\"]\n",
    "            temp_minmaxNorm = (temp_recon-temp_min+1E-16)/(temp_max-temp_min)\n",
    "            nX_test[:,advance:advance+(num_feat*dim)] = temp_minmaxNorm.reshape(len(X_test),num_feat*dim)\n",
    "\n",
    "        if(i==2):\n",
    "            force_mag = np.linalg.norm(temp_recon,axis=1).reshape(len(temp_recon),1)\n",
    "            force_mean = feature_normalization[\"gF_force_per_solvent_mean\"]\n",
    "            force_std = feature_normalization[\"gF_force_per_solvent_std\"]\n",
    "            force_zScoreNorm = (force_mag-force_mean)/(force_std)\n",
    "            force_zScoreNorm = force_zScoreNorm*(1.0/force_mag)*temp_recon\n",
    "            nX_test[:,advance:advance+(num_feat*dim)] = force_zScoreNorm.reshape(len(X_test),num_feat*dim)\n",
    "            \n",
    "        if(i==3):\n",
    "            force_mag = np.linalg.norm(temp_recon,axis=1).reshape(len(temp_recon),1)\n",
    "            force_mean = feature_normalization[\"gF_force_per_solute_atom_mean\"]\n",
    "            force_std = feature_normalization[\"gF_force_per_solute_atom_std\"]\n",
    "            force_zScoreNorm = (force_mag-force_mean)/(force_std)\n",
    "            force_zScoreNorm = force_zScoreNorm*(1.0/force_mag)*temp_recon\n",
    "            nX_test[:,advance:advance+(num_feat*dim)] = force_zScoreNorm.reshape(len(X_test),num_feat*dim)\n",
    "        advance+=(num_feat*dim)\n",
    "        \n",
    "    \n",
    "    np.save(\"DATA/TEST/X_test\",nX_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "\n",
    "    ### STEP 1 ###\n",
    "    \"\"\"    \n",
    "    This first step is step performed to normalize the features before feeding them into the ANN. As a result,\n",
    "    the normalization parameters are saved. These parameters must be used for future data to apply to future\n",
    "    data (i.e. loaded in generate_Normalized_test_features() ).\n",
    "    \"\"\"\n",
    "    #main()\n",
    "\n",
    "    ### STEP 2 ###\n",
    "    \"\"\" \n",
    "    This step is used to properly scale and shift test data to be consistent with the training data.\n",
    "    \"\"\"\n",
    "    generate_Normalized_test_features(\"POS_DFT\",\"FRC_DFT\",500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST CELLS BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(15, 3), (15, 1), (95, 3), (24, 3)]\n",
    "[(15, 3), (15, 1), (95, 3), (24, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.66118872e-02  1.80178320e+00 -2.96182704e+00  2.51345992e-01\n",
      "  1.43509400e+00  2.84603000e-01  4.10471946e-01  6.47507846e-01\n",
      " -2.65584779e+00  5.10221422e-01  1.73429406e+00  2.03423238e+00\n",
      "  5.69994450e-01  2.07993746e+00  8.50595295e-01  6.00226462e-01\n",
      "  2.24841380e+00 -5.86964250e-01  6.12429440e-01  2.39230227e+00\n",
      "  2.72550702e+00  6.29202724e-01  8.40357006e-01 -7.24645197e-01\n",
      "  6.62388563e-01  1.45837998e+00  1.25310934e+00  7.08181083e-01\n",
      "  1.65139210e+00 -9.14409935e-01  7.15275407e-01  1.14977765e+00\n",
      "  2.50871778e+00  8.32504988e-01  1.77373052e+00 -1.97482431e+00\n",
      "  8.36285412e-01  8.20740104e-01  6.71886504e-01  8.63745391e-01\n",
      "  7.49065697e-01 -1.80337882e+00  9.83092546e-01  2.50564122e+00\n",
      "  1.64184654e+00  3.08519542e-01  4.88743931e-01  5.50470591e-01\n",
      "  5.59637547e-01  1.64572284e-01  6.62935078e-01  6.01463974e-01\n",
      "  7.08218575e-01  6.35603666e-01  6.52125061e-01  3.09627980e-01\n",
      "  4.63429600e-01  8.42445135e-01  5.39400995e-01  2.98426986e-01\n",
      " -3.82229537e-01  1.18730687e-01  4.05273110e-01 -1.68427259e-01\n",
      "  3.50202955e-02  2.02287674e-01  2.70462334e-01 -2.05845535e-01\n",
      " -2.84867793e-01  4.32828963e-02  6.73213005e-02  1.03637697e-02\n",
      " -5.43009520e-01 -5.04705131e-01  3.47208112e-01  9.01947245e-02\n",
      " -2.46749893e-01 -4.85607117e-01 -1.20580703e-01  7.44890451e-01\n",
      "  1.27172664e-01 -8.21615756e-02  2.31864024e-03  1.28015485e-02\n",
      " -2.08006576e-01 -3.34535927e-01 -1.43188193e-01 -8.71673524e-02\n",
      " -2.57203370e-01  4.89269733e-01  3.08659393e-02 -1.67299330e-01\n",
      "  3.84515673e-01  6.15668520e-02 -2.66808957e-01  1.69608757e-01\n",
      " -4.28262502e-02 -1.96664035e-02  5.74486673e-01 -1.86914906e-01\n",
      " -6.50190115e-01 -1.07413933e-01 -5.79689801e-01  2.00766876e-01\n",
      " -3.53446066e-01  1.93138212e-01 -2.86547452e-01 -3.42353970e-01\n",
      "  5.77971339e-02  7.44966557e-03 -1.51831768e-02  2.56156266e-01\n",
      " -1.13045163e-01 -2.35832259e-01 -1.38921142e-01 -5.60438752e-01\n",
      "  1.67692751e-02  2.01759294e-01 -2.44689167e-01 -2.79821247e-01\n",
      "  3.53272706e-02  2.12495355e-03  2.16124076e-02  2.79287130e-01\n",
      "  3.07854507e-02 -6.84390664e-02  1.92038029e-01 -2.14329690e-01\n",
      " -1.94325894e-01  1.38246641e-01  3.22499514e-01  6.81094050e-01\n",
      " -7.44181052e-02 -2.33521044e-01  6.24400601e-02  4.25747484e-01\n",
      " -1.29836395e-01  8.39151293e-02 -2.80101627e-01 -8.01290274e-01\n",
      " -2.34376654e-01 -6.06821537e-01 -4.65517282e-01 -1.98318720e-01\n",
      " -3.43675375e-01  4.34728935e-02 -3.56163979e-01 -2.21776381e-01\n",
      "  2.00332776e-01  9.63269025e-02 -7.69578397e-01 -3.56061757e-01\n",
      "  9.43596959e-01 -6.98648840e-02  1.23527691e-01  1.12635650e-01\n",
      "  1.34360418e-01 -7.52934441e-02 -1.22072240e-02  3.79544497e-01\n",
      "  3.92494738e-01 -1.60335824e-01 -1.21671647e-01  1.77897796e-01\n",
      " -2.35430840e-02  1.14286520e-01  2.93877155e-01 -8.17874789e-01\n",
      "  2.47423183e-02 -1.14303522e-01 -9.56979915e-02 -3.41150016e-01\n",
      " -1.03288829e+00 -2.65363842e-01 -1.67753592e-01 -1.41297728e-01\n",
      " -4.03939784e-01 -4.13307063e-02  1.89310223e-01 -2.83454716e-01\n",
      "  3.33329976e-01  1.19324382e-02 -2.46422529e-01 -2.30919242e-01\n",
      "  5.62279671e-02  6.86191797e-01 -3.63545626e-01 -1.41444886e-02\n",
      " -4.41381097e-01  1.07271492e-01 -4.10748497e-02  2.11099926e-02\n",
      " -1.54662067e-02 -2.02622607e-01  1.77221790e-01  4.42935795e-01\n",
      "  6.68114364e-01 -6.77242458e-01 -4.87307459e-02  2.43730709e-01\n",
      " -6.58602044e-02 -5.25295794e-01  6.66473687e-01 -4.32354838e-01\n",
      " -2.36991480e-01  3.75028104e-02  1.47633418e-01 -9.57272410e-01\n",
      "  3.39772515e-02 -4.06617939e-01 -1.74915522e-01  5.52289903e-01\n",
      "  3.96634758e-01 -4.24933493e-01 -5.21902323e-01 -3.61460567e-01\n",
      " -3.09242308e-02 -6.08264878e-02 -8.84500146e-03  5.92000067e-01\n",
      " -5.12963176e-01 -7.38121569e-01 -8.12640563e-02 -5.48793733e-01\n",
      " -1.52685180e-01 -1.67241450e-02  1.71927631e-01 -1.72112323e-02\n",
      "  4.85078484e-01 -5.15397549e-01 -9.72643197e-02 -1.29188225e-01\n",
      "  1.01694912e-01 -8.00683126e-02  7.17679679e-01 -2.34256890e-02\n",
      "  4.13504362e-01 -9.94047225e-02  3.71119261e-01  1.63801029e-01\n",
      " -5.58639526e+00 -1.43068361e+01 -1.63501968e+01 -3.05955894e-02\n",
      "  1.85430497e-02 -1.09916264e-02 -2.04761676e-03 -3.07604432e-01\n",
      "  2.40252778e-01  3.18126470e-01  9.41995859e-01  9.77065638e-02\n",
      " -5.70624053e-01  3.79561514e-01 -1.18431784e-01 -1.11755455e+00\n",
      "  1.95395470e-01  1.00390296e-02  1.64795220e-01 -5.13656378e-01\n",
      " -9.04079340e-03 -2.70707637e-01 -6.91489875e-02  1.95626304e-01\n",
      "  3.23331326e-01  4.45159882e-01  5.76524496e-01 -4.64915857e-02\n",
      "  2.62637854e-01  1.54683620e-01  4.89310294e-01  4.46611285e-01\n",
      "  3.22159603e-02 -6.31363630e-01 -8.41856241e-01  1.03854215e+00\n",
      " -3.77492458e-01 -7.30625808e-01  7.06966370e-02  1.53606057e-01\n",
      "  9.40414146e-02 -3.15557010e-02  2.23590076e-01  2.79697664e-02\n",
      " -3.52531346e-03 -1.77597433e-01 -9.55170318e-02 -3.30233015e-02\n",
      " -6.74897730e-02 -7.09696785e-02  1.92776397e-01 -4.30643678e-01\n",
      "  1.01800831e-02  3.76514792e-02  1.24553338e-01 -1.25679001e-01\n",
      "  2.77418882e-01 -5.93284249e-01 -1.55106112e-01 -4.22693379e-02\n",
      " -8.66683107e-03 -2.13399112e-01  1.72208965e-01 -2.76041925e-02\n",
      " -9.87178236e-02  4.65514250e-02  5.08014411e-02 -1.91292256e-01\n",
      " -6.09039187e-01 -9.60249603e-01  6.06174707e-01 -1.51466411e-02\n",
      "  1.12603540e-02  3.90639715e-03  3.59728374e-03  1.07266617e+00\n",
      "  3.80276442e-01 -4.52280313e-01  2.39565611e-01 -5.46501100e-01\n",
      "  1.61377385e-01 -3.87296945e-01 -4.61982220e-01 -4.48079795e-01\n",
      "  8.27939734e-02 -1.77015126e-01 -9.21585634e-02 -3.54191124e-01\n",
      "  1.13848254e-01 -1.97001606e-01  9.37525257e-02  1.20319262e-01\n",
      "  6.33247569e-02  2.95550764e-01 -7.88739473e-02  6.47768915e-01\n",
      "  1.51646987e-01  4.65655476e-01 -5.23858443e-02 -1.86243311e-01\n",
      "  2.17395201e-01  5.56411922e-01  2.68145843e-04  4.66697896e-03\n",
      " -2.83767178e-04 -5.88230323e-04 -3.75472575e-01  7.59584922e-03\n",
      "  1.68149829e+00  8.53669703e-01  1.28874913e-01 -4.82854731e-02\n",
      " -2.40656137e-01 -1.10643439e-01 -3.50955248e-01  5.39471745e-01\n",
      " -1.55797794e-01  2.92310894e-01 -9.18518126e-01  1.48756489e-01\n",
      " -1.19000003e-01  1.31971288e+00 -7.03294277e-02 -5.67663133e-01\n",
      "  1.12173831e+00  2.36994371e-01  1.93116933e-01 -1.99237299e+00\n",
      "  1.46054821e-02 -1.93337142e-01 -6.27356172e-01 -5.51239289e-02\n",
      "  5.07913530e-01  1.04867816e+00  1.51843363e-02  1.89471319e-01\n",
      " -4.21289951e-01  1.95727512e-01  3.24550837e-01 -5.65856338e-01\n",
      "  1.22820005e-01 -4.14656028e-02 -4.66340547e-03  6.11699186e-04\n",
      " -3.38103920e-01 -3.81464362e-02 -2.38553792e-01 -6.03176415e-01\n",
      " -5.58880508e-01  4.46124107e-01 -2.92397453e-03 -3.17937315e-01\n",
      " -8.75854194e-02  2.03905120e-01  7.39443362e-01  2.16896549e-01\n",
      "  4.38384190e-02 -1.76946819e-01 -1.94940101e-02  3.21936995e-01\n",
      "  4.12166774e-01 -1.57321423e-01 -1.97678760e-01 -1.15730166e-01\n",
      " -7.53068924e-02 -1.50797181e-02 -1.95296407e-01  2.57987157e-02\n",
      " -6.15149319e-01 -8.04251552e-01 -1.44137472e-01  1.93276659e-01\n",
      " -8.81016329e-02  1.26431778e-01  4.00207698e-01 -1.09766626e+00\n",
      " -5.73511362e-01]\n"
     ]
    }
   ],
   "source": [
    "npX_train = np.load(\"DATA/X_train.npy\").astype(np.float32)\n",
    "\n",
    "print(npX_train[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499, 432)\n",
      "(3, 15, 499)\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "print(np.shape(featurearray))\n",
    "print(np.shape(featurearray[:,advance:advance+(temp_feature_shapes[i][0]*temp_feature_shapes[i][1])].reshape((np.shape(featurearray)[0],-1,temp_feature_shapes[i][1])).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.8194768 , 5.54294444, 5.9688347 , 6.36782186, 6.90161912,\n",
       "       3.8194768 , 4.46423767, 5.12729886, 5.54294444, 5.79201256,\n",
       "       5.91798603, 5.9688347 , 6.03872732, 6.17700918, 6.36782186])"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurearray[:,advance:advance+(temp_feature_shapes[i][0]*temp_feature_shapes[i][1])].reshape((np.shape(featurearray)[0],-1,temp_feature_shapes[i][1])).T[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define new X axis\n",
    "newX = 0.5*(cwPOS[16]+cwPOS[18])\n",
    "newX = (1.0/np.linalg.norm(newX))*newX\n",
    "#Use a second point to define the plane.\n",
    "#I.e. find a vector n orthogonal to a that is in the plane which contains a and b.\n",
    "refY = cwPOS[7]\n",
    "newY = np.cross(newX,np.cross(newX,(1.0/np.linalg.norm(refY))*refY))\n",
    "newY = (1.0/np.linalg.norm(newY))*newY\n",
    "\n",
    "#Define new Z as perpendicular to plane defined by newX and newY\n",
    "newZ = np.cross(newX,newY)\n",
    "newZ = (1.0/np.linalg.norm(newZ)*newZ)\n",
    "\n",
    "#Apply reoriented molecules\n",
    "alpha,beta,gamma = reorient_molecule(cwPOS,newX,newY,newZ)\n",
    "\n",
    "#Define Rotation Matrix (Z1X2Z3, Euler Angles)\n",
    "\n",
    "RotMatrix = np.array([[np.cos(alpha)*np.cos(gamma)-np.cos(beta)*np.sin(alpha)*np.sin(gamma),-np.cos(alpha)*np.sin(gamma)-np.cos(beta)*np.cos(gamma)*np.sin(alpha),np.sin(alpha)*np.sin(beta)],\n",
    "                      [np.cos(gamma)*np.sin(alpha)+np.cos(alpha)*np.cos(beta)*np.sin(gamma),np.cos(alpha)*np.cos(beta)*np.cos(gamma)-np.sin(alpha)*np.sin(gamma),-np.cos(alpha)*np.sin(beta)],\n",
    "                      [np.sin(beta)*np.sin(gamma),np.cos(gamma)*np.sin(beta),np.cos(beta)]])\n",
    "\n",
    "test_rotation = np.matmul(RotMatrix,np.transpose(cwPOS)).transpose()\n",
    "\n",
    "\n",
    "#test_roated_and_wrapped = wrap_cell(test_rotation,metadata,rot_translation_vectors)\n",
    "#recon_rot_wrap,_,_ = generate_solvent_COMs(test_roated_and_wrapped,metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_vectors = np.array([[metadata[\"box_length\"],0.0,0.0],[0.0,metadata[\"box_length\"],0.0],[metadata[\"box_length\"],0.0,0.0]])\n",
    "rot_translation_vectors = np.matmul(RotMatrix,np.transpose(translation_vectors)).transpose()\n",
    "\n",
    "rot_translation_vectors\n",
    "\n",
    "#print(np.dot(a1,a2))\n",
    "#print(np.linalg.norm(a1))\n",
    "#cosine_angle = np.dot(a1, a2) / (np.linalg.norm(a1) * np.linalg.norm(a2))\n",
    "#solvent_angles[i] = np.arccos(cosine_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dihedrals_and_centers,gF_dihedrals)\n",
    "u1,u2,u3,u4 = cwPOS[dihedrals_and_centers[0]]\n",
    "#print(u1,u2,u3,u4,gF_dihedrals)\n",
    "#dihedrals_and_centers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "topology = metadata[\"topology_solute\"]\n",
    "\n",
    "dihedrals_and_centers = []\n",
    "\n",
    "for pair1 in range(len(topology)-2):\n",
    "    for pair2 in range(pair1+1,len(topology)-1):\n",
    "        for pair3 in range(pair2+1,len(topology)):\n",
    "            result_list = list(topology[pair1])\n",
    "            result_list.extend(x for x in topology[pair2] if x not in result_list )\n",
    "            result_list.extend(x for x in topology[pair3] if x not in result_list[2:] )\n",
    "            if(len(result_list)==4):\n",
    "                dihedrals_and_centers.append(result_list)\n",
    "                \n",
    "for four_atoms in dihedrals_and_centers:\n",
    "    for i in topology:\n",
    "        if [four_atoms[0],four_atoms[2]] == i:\n",
    "            four_atoms[0],four_atoms[1] = four_atoms[1], four_atoms[0]\n",
    "\n",
    "#dihedrals_and_centers\n",
    "\n",
    "#    if set(tuple(x) for x in topology_reverse).intersection(four_atoms[1:3]):\n",
    "#        #print(\"switch\",four_atoms,four_atoms[1:3],pair)\n",
    "#        \n",
    "#        print(four_atoms,list(set(four_atoms[1:3]).intersection(pair)),pair)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "solute_and_nearest = np.zeros(((metadata[\"n_atoms_solute\"]+len(metadata[\"solvent_indices\"])*15),3))\n",
    "solute_and_nearest[:metadata[\"n_atoms_solute\"],:] = cwPOS[:metadata[\"n_atoms_solute\"],:]\n",
    "for i, solv_index in enumerate(nearest_15_solv_index):\n",
    "    solute_and_nearest[metadata[\"n_atoms_solute\"]+i*len(metadata[\"solvent_indices\"]):\n",
    "                       metadata[\"n_atoms_solute\"]+(i+1)*len(metadata[\"solvent_indices\"]),:] = cwPOS[metadata[\"n_atoms_solute\"]+solv_index*len(metadata[\"solvent_indices\"]):\n",
    "                       metadata[\"n_atoms_solute\"]+(solv_index+1)*len(metadata[\"solvent_indices\"]),:]\n",
    "\n",
    "solute_and_nearest = np.matmul(RotMatrix,np.transpose(solute_and_nearest)).transpose()\n",
    "write_xyz(\"AQ-_15nearestACN.xyz\", solute_and_nearest, title=\"\", atomtypes=AtomNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_xyz('cwPOS_reconSolv_test.xyz', h, title=\"\", atomtypes=AtomNames)\n",
    "write_xyz('solventCOMs_test.xyz', solvent_COM, title=\"\", atomtypes=95*[\"X\"])\n",
    "\n",
    "write_xyz(\"cPOS.xyz\", cPOS, title=\"\", atomtypes=AtomNames)\n",
    "write_xyz(\"cwPOS.xyz\", cwPOS, title=\"\", atomtypes=AtomNames)\n",
    "\n",
    "write_xyz(\"test_roated_and_wrapped.xyz\", test_roated_and_wrapped, title=\"\", atomtypes=AtomNames)\n",
    "write_xyz(\"recon_rot_wrap.xyz\", recon_rot_wrap, title=\"\", atomtypes=AtomNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomtypes=95*[\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(15, 1), (15, 3), (15, 1), (95, 3), (24, 3)]\n"
     ]
    }
   ],
   "source": [
    "print(temp_feature_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
